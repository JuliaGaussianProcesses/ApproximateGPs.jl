<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · ApproximateGPs.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><script src="../../copy.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ApproximateGPs.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../userguide/">User Guide</a></li><li class="is-active"><a class="tocitem" href>API</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/a-regression/">Regression: Sparse Variational Gaussian Process for Stochastic Optimisation with Flux.jl</a></li><li><a class="tocitem" href="../examples/b-classification/">Classification: Sparse Variational Approximation for Non-Conjugate Likelihoods with Optim&#39;s L-BFGS</a></li><li><a class="tocitem" href="../examples/c-comparisons/">Binary Classification with Laplace approximation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/master/docs/src/api.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="ApproximateGPs-API"><a class="docs-heading-anchor" href="#ApproximateGPs-API">ApproximateGPs API</a><a id="ApproximateGPs-API-1"></a><a class="docs-heading-anchor-permalink" href="#ApproximateGPs-API" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.Centered" href="#ApproximateGPs.Centered"><code>ApproximateGPs.Centered</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Centered()</code></pre><p>Used in conjunction with <code>SparseVariationalApproximation</code>. States that the <code>q</code> field of <a href="#ApproximateGPs.SparseVariationalApproximation-Tuple{AbstractGPs.FiniteGP, Distributions.AbstractMvNormal}"><code>SparseVariationalApproximation</code></a> is to be interpreted directly as the approximate posterior over the pseudo-points.</p><p>This is also known as the &quot;unwhitened&quot; parametrization [1].</p><p>See also <a href="#ApproximateGPs.NonCentered"><code>NonCentered</code></a>.</p><p>[1] - https://en.wikipedia.org/wiki/Whitening_transformation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.NonCentered" href="#ApproximateGPs.NonCentered"><code>ApproximateGPs.NonCentered</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NonCentered()</code></pre><p>Used in conjunction with <code>SparseVariationalApproximation</code>. States that the <code>q</code> field of <a href="#ApproximateGPs.SparseVariationalApproximation-Tuple{AbstractGPs.FiniteGP, Distributions.AbstractMvNormal}"><code>SparseVariationalApproximation</code></a> is to be interpreted as the approximate posterior over <code>cholesky(cov(u)).L \ (u - mean(u))</code>, where <code>u</code> are the pseudo-points.</p><p>This is also known as the &quot;whitened&quot; parametrization [1].</p><p>See also <a href="#ApproximateGPs.Centered"><code>Centered</code></a>.</p><p>[1] - https://en.wikipedia.org/wiki/Whitening_transformation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L16-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.SparseVariationalApproximation-Tuple{AbstractGPs.FiniteGP, Distributions.AbstractMvNormal}" href="#ApproximateGPs.SparseVariationalApproximation-Tuple{AbstractGPs.FiniteGP, Distributions.AbstractMvNormal}"><code>ApproximateGPs.SparseVariationalApproximation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SparseVariationalApproximation(fz::FiniteGP, q::AbstractMvNormal)</code></pre><p>Packages the prior over the pseudo-points <code>fz</code>, and the approximate posterior at the pseudo-points, which is <code>mean(fz) + cholesky(cov(fz)).L * ε</code>, <code>ε ∼ q</code>.</p><p>Shorthand for</p><pre><code class="language-julia hljs">SparseVariationalApproximation(NonCentered(), fz, q)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L55-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.SparseVariationalApproximation-Union{Tuple{Tq}, Tuple{Tfz}, Tuple{Parametrization}, Tuple{Parametrization, Tfz, Tq}} where {Parametrization, Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}" href="#ApproximateGPs.SparseVariationalApproximation-Union{Tuple{Tq}, Tuple{Tfz}, Tuple{Parametrization}, Tuple{Parametrization, Tfz, Tq}} where {Parametrization, Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}"><code>ApproximateGPs.SparseVariationalApproximation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">SparseVariationalApproximation(
    ::Parametrization, fz::FiniteGP, q::AbstractMvNormal
) where {Parametrization}</code></pre><p>Produce a <code>SparseVariationalApproximation{Parametrization}</code>, which packages the prior over the pseudo-points, <code>fz</code>, and the approximate posterior at the pseudo-points, <code>q</code>, together into a single object.</p><p>The <code>Parametrization</code> determines the precise manner in which <code>q</code> and <code>fz</code> are interpreted. Existing parametrizations include <a href="#ApproximateGPs.Centered"><code>Centered</code></a> and <a href="#ApproximateGPs.NonCentered"><code>NonCentered</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L37-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.FiniteGP{var&quot;#s33&quot;, var&quot;#s34&quot;, var&quot;#s35&quot;} where {var&quot;#s33&quot;&lt;:AbstractGPs.AbstractGP, var&quot;#s34&quot;&lt;:(AbstractVector{T} where T), var&quot;#s35&quot;&lt;:(LinearAlgebra.Diagonal{var&quot;#s36&quot;, var&quot;#s37&quot;} where {var&quot;#s36&quot;&lt;:Real, var&quot;#s37&quot;&lt;:FillArrays.Fill})}, AbstractVector{var&quot;#s38&quot;} where var&quot;#s38&quot;&lt;:Real}" href="#AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.FiniteGP{var&quot;#s33&quot;, var&quot;#s34&quot;, var&quot;#s35&quot;} where {var&quot;#s33&quot;&lt;:AbstractGPs.AbstractGP, var&quot;#s34&quot;&lt;:(AbstractVector{T} where T), var&quot;#s35&quot;&lt;:(LinearAlgebra.Diagonal{var&quot;#s36&quot;, var&quot;#s37&quot;} where {var&quot;#s36&quot;&lt;:Real, var&quot;#s37&quot;&lt;:FillArrays.Fill})}, AbstractVector{var&quot;#s38&quot;} where var&quot;#s38&quot;&lt;:Real}"><code>AbstractGPs.elbo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">elbo(
    sva::SparseVariationalApproximation,
    fx::FiniteGP,
    y::AbstractVector{&lt;:Real};
    num_data=length(y),
    quadrature=DefaultQuadrature(),
)</code></pre><p>Compute the Evidence Lower BOund from [1] for the process <code>f = fx.f == svgp.fz.f</code> where <code>y</code> are observations of <code>fx</code>, pseudo-inputs are given by <code>z = svgp.fz.x</code> and <code>q(u)</code> is a variational distribution over inducing points <code>u = f(z)</code>.</p><p><code>quadrature</code> selects which method is used to calculate the expected loglikelihood in the ELBO. The options are: <code>DefaultQuadrature()</code>, <code>Analytic()</code>, <code>GaussHermite()</code> and <code>MonteCarlo()</code>. For likelihoods with an analytic solution, <code>DefaultQuadrature()</code> uses this exact solution. If there is no such solution, <code>DefaultQuadrature()</code> either uses <code>GaussHermite()</code> or <code>MonteCarlo()</code>, depending on the likelihood.</p><p>N.B. the likelihood is assumed to be Gaussian with observation noise <code>fx.Σy</code>. Further, <code>fx.Σy</code> must be isotropic - i.e. <code>fx.Σy = α * I</code>.</p><p>[1] - Hensman, James, Alexander Matthews, and Zoubin Ghahramani. &quot;Scalable variational Gaussian process classification.&quot; Artificial Intelligence and Statistics. PMLR, 2015.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L242-L268">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.LatentFiniteGP, AbstractVector{T} where T}" href="#AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.LatentFiniteGP, AbstractVector{T} where T}"><code>AbstractGPs.elbo</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">elbo(
    sva::SparseVariationalApproximation,
    lfx::LatentFiniteGP,
    y::AbstractVector;
    num_data=length(y),
    quadrature=DefaultQuadrature(),
)</code></pre><p>Compute the ELBO for a LatentGP with a possibly non-conjugate likelihood.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L290-L300">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{LaplaceApproximation, AbstractGPs.LatentFiniteGP, Any}" href="#AbstractGPs.posterior-Tuple{LaplaceApproximation, AbstractGPs.LatentFiniteGP, Any}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">posterior(la::LaplaceApproximation, lfx::LatentFiniteGP, ys)</code></pre><p>Construct a Gaussian approximation <code>q(f)</code> to the posterior <code>p(f | y)</code> using the Laplace approximation. Solves for a mode of the posterior using Newton&#39;s method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L13-L19">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{SparseVariationalApproximation{Centered, Tfz, Tq} where {Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}}" href="#AbstractGPs.posterior-Tuple{SparseVariationalApproximation{Centered, Tfz, Tq} where {Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">posterior(sva::SparseVariationalApproximation{Centered})</code></pre><p>Compute the approximate posterior [1] over the process <code>f = sva.fz.f</code>, given inducing inputs <code>z = sva.fz.x</code> and a variational distribution over inducing points <code>sva.q</code> (which represents <span>$q(u)$</span> where <code>u = f(z)</code>). The approximate posterior at test points <span>$x^*$</span> where <span>$f^* = f(x^*)$</span> is then given by:</p><p class="math-container">\[q(f^*) = \int p(f | u) q(u) du\]</p><p>which can be found in closed form.</p><p>[1] - Hensman, James, Alexander Matthews, and Zoubin Ghahramani. &quot;Scalable variational Gaussian process classification.&quot; Artificial Intelligence and Statistics. PMLR, 2015.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L70-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="AbstractGPs.posterior-Tuple{SparseVariationalApproximation{NonCentered, Tfz, Tq} where {Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}}" href="#AbstractGPs.posterior-Tuple{SparseVariationalApproximation{NonCentered, Tfz, Tq} where {Tfz&lt;:AbstractGPs.FiniteGP, Tq&lt;:Distributions.AbstractMvNormal}}"><code>AbstractGPs.posterior</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">posterior(sva::SparseVariationalApproximation{NonCentered})</code></pre><p>Compute the approximate posterior [1] over the process <code>f = sva.fz.f</code>, given inducing inputs <code>z = sva.fz.x</code> and a variational distribution over inducing points <code>sva.q</code> (which represents <span>$q(ε)$</span> where <code>ε = cholesky(cov(fz)).L \ (f(z) - mean(f(z)))</code>). The approximate posterior at test points <span>$x^*$</span> where <span>$f^* = f(x^*)$</span> is then given by:</p><p class="math-container">\[q(f^*) = \int p(f | ε) q(ε) du\]</p><p>which can be found in closed form.</p><p>[1] - Hensman, James, Alexander Matthews, and Zoubin Ghahramani. &quot;Scalable variational Gaussian process classification.&quot; Artificial Intelligence and Statistics. PMLR, 2015.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/sparse_variational.jl#L115-L132">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.approx_lml-Tuple{LaplaceApproximation, AbstractGPs.LatentFiniteGP, Any}" href="#ApproximateGPs.approx_lml-Tuple{LaplaceApproximation, AbstractGPs.LatentFiniteGP, Any}"><code>ApproximateGPs.approx_lml</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">approx_lml(la::LaplaceApproximation, lfx::LatentFiniteGP, ys)</code></pre><p>Compute an approximation to the log of the marginal likelihood (also known as &quot;evidence&quot;), which can be used to optimise the hyperparameters of <code>lfx</code>.</p><p>This should become part of the AbstractGPs API (see JuliaGaussianProcesses/AbstractGPs.jl#221).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L31-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.build_laplace_objective-Tuple{Any, Any, Any}" href="#ApproximateGPs.build_laplace_objective-Tuple{Any, Any, Any}"><code>ApproximateGPs.build_laplace_objective</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">build_laplace_objective(build_latent_gp, xs, ys; kwargs...)</code></pre><p>Construct a closure that computes the minimisation objective for optimising hyperparameters of the latent GP in the Laplace approximation. The returned closure passes its arguments to <code>build_latent_gp</code>, which must return the <code>LatentGP</code> prior.</p><p><strong>Keyword arguments</strong></p><ul><li><code>newton_warmstart=true</code>: (default) begin Newton optimisation at the mode of the previous call to the objective</li><li><code>newton_callback</code>: called as <code>newton_callback(fnew, cache)</code> after each Newton step</li><li><code>newton_maxiter=100</code>: maximum number of Newton steps.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L43-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.expected_loglik-NTuple{4, Any}" href="#ApproximateGPs.expected_loglik-NTuple{4, Any}"><code>ApproximateGPs.expected_loglik</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">expected_loglik(quadrature::QuadratureMethod, y::AbstractVector, q_f::AbstractVector{&lt;:Normal}, lik)</code></pre><p>This function computes the expected log likelihood:</p><p class="math-container">\[    ∫ q(f) log p(y | f) df\]</p><p>where <code>p(y | f)</code> is the process likelihood. This is described by <code>lik</code>, which should be a callable that takes <code>f</code> as input and returns a Distribution over <code>y</code> that supports <code>loglikelihood(lik(f), y)</code>.</p><p><code>q(f)</code> is an approximation to the latent function values <code>f</code> given by:</p><p class="math-container">\[    q(f) = ∫ p(f | u) q(u) du\]</p><p>where <code>q(u)</code> is the variational distribution over inducing points (see <a href="#AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.FiniteGP{var&quot;#s33&quot;, var&quot;#s34&quot;, var&quot;#s35&quot;} where {var&quot;#s33&quot;&lt;:AbstractGPs.AbstractGP, var&quot;#s34&quot;&lt;:(AbstractVector{T} where T), var&quot;#s35&quot;&lt;:(LinearAlgebra.Diagonal{var&quot;#s36&quot;, var&quot;#s37&quot;} where {var&quot;#s36&quot;&lt;:Real, var&quot;#s37&quot;&lt;:FillArrays.Fill})}, AbstractVector{var&quot;#s38&quot;} where var&quot;#s38&quot;&lt;:Real}"><code>elbo</code></a>). The marginal distributions of <code>q(f)</code> are given by <code>q_f</code>.</p><p><code>quadrature</code> determines which method is used to calculate the expected log likelihood - see <a href="#AbstractGPs.elbo-Tuple{SparseVariationalApproximation, AbstractGPs.FiniteGP{var&quot;#s33&quot;, var&quot;#s34&quot;, var&quot;#s35&quot;} where {var&quot;#s33&quot;&lt;:AbstractGPs.AbstractGP, var&quot;#s34&quot;&lt;:(AbstractVector{T} where T), var&quot;#s35&quot;&lt;:(LinearAlgebra.Diagonal{var&quot;#s36&quot;, var&quot;#s37&quot;} where {var&quot;#s36&quot;&lt;:Real, var&quot;#s37&quot;&lt;:FillArrays.Fill})}, AbstractVector{var&quot;#s38&quot;} where var&quot;#s38&quot;&lt;:Real}"><code>elbo</code></a> for more details.</p><p><strong>Extended help</strong></p><p><code>q(f)</code> is assumed to be an <code>MvNormal</code> distribution and <code>p(y | f)</code> is assumed to have independent marginals such that only the marginals of <code>q(f)</code> are required.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/expected_loglik.jl#L17-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.expected_loglik-Tuple{DefaultQuadrature, AbstractVector{T} where T, AbstractVector{var&quot;#s7&quot;} where var&quot;#s7&quot;&lt;:Distributions.Normal, Any}" href="#ApproximateGPs.expected_loglik-Tuple{DefaultQuadrature, AbstractVector{T} where T, AbstractVector{var&quot;#s7&quot;} where var&quot;#s7&quot;&lt;:Distributions.Normal, Any}"><code>ApproximateGPs.expected_loglik</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">expected_loglik(::DefaultQuadrature, y::AbstractVector, q_f::AbstractVector{&lt;:Normal}, lik)</code></pre><p>The expected log likelihood. Defaults to a closed form solution if it exists, otherwise defaults to Gauss-Hermite quadrature.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/expected_loglik.jl#L44-L50">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.laplace_f_and_lml-Tuple{AbstractGPs.LatentFiniteGP, Any}" href="#ApproximateGPs.laplace_f_and_lml-Tuple{AbstractGPs.LatentFiniteGP, Any}"><code>ApproximateGPs.laplace_f_and_lml</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">laplace_f_and_lml(lfx::LatentFiniteGP, ys; newton_kwargs...)</code></pre><p>Compute a mode of the posterior and the Laplace approximation to the log marginal likelihood.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L101-L106">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.laplace_f_cov-Tuple{Any}" href="#ApproximateGPs.laplace_f_cov-Tuple{Any}"><code>ApproximateGPs.laplace_f_cov</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">laplace_f_cov(cache)</code></pre><p>Compute the covariance of <code>q(f)</code> from the results of the training computation that are stored in a <code>LaplaceCache</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L327-L332">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.laplace_lml-Tuple{AbstractGPs.LatentFiniteGP, Any}" href="#ApproximateGPs.laplace_lml-Tuple{AbstractGPs.LatentFiniteGP, Any}"><code>ApproximateGPs.laplace_lml</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">laplace_lml(lfx::LatentFiniteGP, ys; newton_kwargs...)</code></pre><p>Compute the Laplace approximation to the log marginal likelihood.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L114-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.laplace_steps-Tuple{AbstractGPs.LatentFiniteGP, Any}" href="#ApproximateGPs.laplace_steps-Tuple{AbstractGPs.LatentFiniteGP, Any}"><code>ApproximateGPs.laplace_steps</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">laplace_steps(lfx::LatentFiniteGP, ys; newton_kwargs...)</code></pre><p>For demonstration purposes: returns an array of all the intermediate approximations of each Newton step.</p><p>If you are only interested in the actual posterior, use <code>posterior(::LaplaceApproximation, ...</code>.</p><p>TODO figure out how to get the <code>@ref</code> to work to point to the LaplaceApproximation-specific <code>posterior</code> docstring...</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L354-L364">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.loglik_and_derivs-Tuple{Any, AbstractVector{T} where T, AbstractVector{var&quot;#s39&quot;} where var&quot;#s39&quot;&lt;:Real}" href="#ApproximateGPs.loglik_and_derivs-Tuple{Any, AbstractVector{T} where T, AbstractVector{var&quot;#s39&quot;} where var&quot;#s39&quot;&lt;:Real}"><code>ApproximateGPs.loglik_and_derivs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loglik_and_derivs(dist_y_given_f, ys, f)</code></pre><p><code>dist_y_given_f</code> must be a scalar function from a Real to a Distribution object. <code>ys</code> and <code>f</code> are vectors of observations and latent function values, respectively.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L184-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="ApproximateGPs.newton_inner_loop-Tuple{Any, Any, Any}" href="#ApproximateGPs.newton_inner_loop-Tuple{Any, Any, Any}"><code>ApproximateGPs.newton_inner_loop</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">newton_inner_loop(dist_y_given_f, ys, K; f_init, maxiter, callback=nothing)</code></pre><p>Find a mode of <code>p(f | y)</code> using Newton&#39;s method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/bae0a1ebe1865a9eba572ea86a7adbc75cd79387/src/laplace.jl#L259-L263">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../userguide/">« User Guide</a><a class="docs-footer-nextpage" href="../examples/a-regression/">Regression: Sparse Variational Gaussian Process for Stochastic Optimisation with Flux.jl »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.12 on <span class="colophon-date" title="Tuesday 1 February 2022 12:08">Tuesday 1 February 2022</span>. Using Julia version 1.6.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
