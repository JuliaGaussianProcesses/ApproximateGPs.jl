<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>User Guide · ApproximateGPs.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">ApproximateGPs.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>User Guide</a><ul class="internal"><li><a class="tocitem" href="#Setup"><span>Setup</span></a></li><li><a class="tocitem" href="#Constructing-a-sparse-approximation"><span>Constructing a sparse approximation</span></a></li><li><a class="tocitem" href="#The-Evidence-Lower-Bound-(ELBO)"><span>The Evidence Lower Bound (ELBO)</span></a></li><li class="toplevel"><a class="tocitem" href="#Available-Parametrizations"><span>Available Parametrizations</span></a></li></ul></li><li><span class="tocitem">API</span><ul><li><a class="tocitem" href="../api/">ApproximateGPs API</a></li><li><a class="tocitem" href="../api/sparsevariational/">Sparse Variational Approximation</a></li><li><a class="tocitem" href="../api/laplace/">Laplace Approximation</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/a-regression/">Regression: Sparse Variational Gaussian Process for Stochastic Optimisation with Flux.jl</a></li><li><a class="tocitem" href="../examples/b-classification/">Classification: Sparse Variational Approximation for Non-Conjugate Likelihoods with Optim&#39;s L-BFGS</a></li><li><a class="tocitem" href="../examples/c-comparisons/">Binary Classification with Laplace approximation</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>User Guide</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>User Guide</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGaussianProcesses/ApproximateGPs.jl/blob/master/docs/src/userguide.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="User-Guide"><a class="docs-heading-anchor" href="#User-Guide">User Guide</a><a id="User-Guide-1"></a><a class="docs-heading-anchor-permalink" href="#User-Guide" title="Permalink"></a></h1><h2 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h2><p>ApproximateGPs builds on top of <a href="https://juliagaussianprocesses.github.io/AbstractGPs.jl/dev/">AbstractGPs.jl</a>, so all of its features are reexported automatically by ApproximateGPs.</p><pre><code class="language-julia hljs">using ApproximateGPs, Random
rnd = MersenneTwister(1453)  # set a random seed</code></pre><p>First, we construct a prior Gaussian process with a Matern-3/2 kernel and zero mean function, and sample some data. More exotic kernels can be constructed using <a href="https://juliagaussianprocesses.github.io/KernelFunctions.jl/stable/userguide/">KernelFunctions.jl</a>.</p><pre><code class="language-julia hljs">f = GP(Matern32Kernel())

x = rand(rng, 100)
fx = f(x, 0.1)  # Observe the GP with Gaussian observation noise (σ² = 0.1)
y = rand(rng, f(x))  # Sample from the GP prior at x</code></pre><h3 id="The-exact-GP-posterior"><a class="docs-heading-anchor" href="#The-exact-GP-posterior">The exact GP posterior</a><a id="The-exact-GP-posterior-1"></a><a class="docs-heading-anchor-permalink" href="#The-exact-GP-posterior" title="Permalink"></a></h3><p>The exact posterior of <code>f</code> conditioned on <code>y</code> at inputs <code>x</code> is given by</p><pre><code class="language-julia hljs">exact_posterior = posterior(fx, y)</code></pre><h2 id="Constructing-a-sparse-approximation"><a class="docs-heading-anchor" href="#Constructing-a-sparse-approximation">Constructing a sparse approximation</a><a id="Constructing-a-sparse-approximation-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-a-sparse-approximation" title="Permalink"></a></h2><p>To construct a sparse approximation to the exact posterior, we first need to select some inducing inputs. In this case, we simply pick a subset of the training data, but more sophisticated schemes for inducing point selection are provided in <a href="https://juliagaussianprocesses.github.io/InducingPoints.jl/stable/">InducingPoints.jl</a>.</p><pre><code class="language-julia hljs">M = 15  # The number of inducing points
z = x[1:M]</code></pre><p>The inducing inputs <code>z</code> imply some latent function values <code>u = f(z)</code>, sometimes called pseudo-points. The <a href="../api/sparsevariational/#ApproximateGPs.SparseVariationalApproximationModule.SparseVariationalApproximation-Tuple{AbstractGPs.FiniteGP, Distributions.AbstractMvNormal}"><code>SparseVariationalApproximation</code></a> specifies a distribution <code>q(u)</code> over the pseudo-points. In the case of GP regression, the optimal form for <code>q(u)</code> is a multivariate Gaussian, which is the only form of <code>q</code> currently supported by this package.</p><pre><code class="language-julia hljs">using Distributions, LinearAlgebra
q = MvNormal(zeros(length(z)), I)</code></pre><p>Finally, we pass our <code>q</code> along with the inputs <code>f(z)</code> to obtain an approximate posterior GP:</p><pre><code class="language-julia hljs">fz = f(z, 1e-6)  # &#39;observe&#39; the process at z with some jitter for numerical stability 
approx = SparseVariationalApproximation(fz, q)  # Instantiate everything needed for the approximation

sva_posterior = posterior(approx)  # Create the approximate posterior</code></pre><h2 id="The-Evidence-Lower-Bound-(ELBO)"><a class="docs-heading-anchor" href="#The-Evidence-Lower-Bound-(ELBO)">The Evidence Lower Bound (ELBO)</a><a id="The-Evidence-Lower-Bound-(ELBO)-1"></a><a class="docs-heading-anchor-permalink" href="#The-Evidence-Lower-Bound-(ELBO)" title="Permalink"></a></h2><p>The approximate posterior constructed above will be a very poor approximation, since <code>q</code> was simply chosen to have zero mean and covariance <code>I</code>. A measure of the quality of the approximation is given by the ELBO. Optimising this term with respect to the parameters of <code>q</code> and the inducing input locations <code>z</code> will improve the approximation.</p><pre><code class="language-julia hljs">elbo(SparseVariationalApproximation(fz, q), fx, y)</code></pre><p>A detailed example of how to carry out such optimisation is given in <a href="../examples/a-regression/#Regression:-Sparse-Variational-Gaussian-Process-for-Stochastic-Optimisation-with-Flux.jl">Regression: Sparse Variational Gaussian Process for Stochastic Optimisation with Flux.jl</a>. For an example of non-conjugate inference, see <a href="../examples/b-classification/#Classification:-Sparse-Variational-Approximation-for-Non-Conjugate-Likelihoods-with-Optim&#39;s-L-BFGS">Classification: Sparse Variational Approximation for Non-Conjugate Likelihoods with Optim&#39;s L-BFGS</a>.</p><h1 id="Available-Parametrizations"><a class="docs-heading-anchor" href="#Available-Parametrizations">Available Parametrizations</a><a id="Available-Parametrizations-1"></a><a class="docs-heading-anchor-permalink" href="#Available-Parametrizations" title="Permalink"></a></h1><p>Two parametrizations of <code>q(u)</code> are presently available: <a href="../api/sparsevariational/#ApproximateGPs.SparseVariationalApproximationModule.Centered"><code>Centered</code></a> and <a href="../api/sparsevariational/#ApproximateGPs.SparseVariationalApproximationModule.NonCentered"><code>NonCentered</code></a>. The <code>Centered</code> parametrization expresses <code>q(u)</code> directly in terms of its mean and covariance. The <code>NonCentered</code> parametrization instead parametrizes the mean and covariance of <code>ε := cholesky(cov(u)).U&#39; \ (u - mean(u))</code>. These parametrizations are also known respectively as &quot;Unwhitened&quot; and &quot;Whitened&quot;.</p><p>The choice of parametrization can have a substantial impact on the time it takes for ELBO optimization to converge, and which parametrization is better in a particular situation is not generally obvious. That being said, the <code>NonCentered</code> parametrization often converges in fewer iterations, so it is the default – it is what is used in all of the examples above.</p><p>If you require a particular parametrization, simply use the 3-argument version of the approximation constructor:</p><pre><code class="language-julia hljs">SparseVariationalApproximation(Centered(), fz, q)
SparseVariationalApproximation(NonCentered(), fz, q)</code></pre><p>For a general discussion around these two parametrizations, see e.g. <sup class="footnote-reference"><a id="citeref-Gorinova" href="#footnote-Gorinova">[Gorinova]</a></sup>. For a GP-specific discussion, see e.g. section 3.4 of <sup class="footnote-reference"><a id="citeref-Paciorek" href="#footnote-Paciorek">[Paciorek]</a></sup>.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Gorinova"><a class="tag is-link" href="#citeref-Gorinova">Gorinova</a>Gorinova, Maria and Moore, Dave and Hoffman, Matthew <a href="http://proceedings.mlr.press/v119/gorinova20a">Automatic Reparameterisation of Probabilistic Programs</a></li><li class="footnote" id="footnote-Paciorek"><a class="tag is-link" href="#citeref-Paciorek">Paciorek</a><a href="https://www.stat.berkeley.edu/~paciorek/diss/paciorek-thesis.pdf">Paciorek, Christopher Joseph. Nonstationary Gaussian processes for regression and spatial modelling. Diss. Carnegie Mellon University, 2003.</a></li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../api/">ApproximateGPs API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Tuesday 11 April 2023 12:36">Tuesday 11 April 2023</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
